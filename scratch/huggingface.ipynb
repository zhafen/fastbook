{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Notebook for Integrating with Hugging Face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Future work may include using `Arthur bench` to compare LLMS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Re-enable functionality for traditional text-summarization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import huggingface_hub as hfhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sciterra import Atlas\n",
    "from sciterra import Cartographer\n",
    "from sciterra.librarians import SemanticScholarLibrarian # or ADSLibrarian\n",
    "from sciterra.vectorization import SciBERTVectorizer # among others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "config = dict(\n",
    "    atlas_dirpath = \"../atlas\",\n",
    "    model = \"Falconsai/text_summarization\",\n",
    "    endpoint = \"llama-2-7b-chat-hf-mhj\",\n",
    "    api_or_endpoint = 'endpoint',\n",
    "    n_summarized = 10,\n",
    "    task = \"summarization\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_key = {\n",
    "    \"summarization\": \"text_summary\",\n",
    "    \"text-generation\": \"generated_text\",\n",
    "}[config[\"task\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sciterra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atl = Atlas.load(config['atlas_dirpath'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cartographer with a Semantic Scholar librarian and a SciBERT vectorizer\n",
    "crt = Cartographer(\n",
    "    librarian=SemanticScholarLibrarian(),\n",
    "    vectorizer=SciBERTVectorizer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HFHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login\n",
    "token = hfhub.get_token()\n",
    "if token is None:\n",
    "    hfhub.login()\n",
    "    token = hfhub.get_token()\n",
    "\n",
    "# Format for Inference API\n",
    "headers = {\"Authorization\": f\"Bearer {token}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['api_or_endpoint'] == 'api':\n",
    "\n",
    "\tassert False, \"This needs to be fixed up again.\"\n",
    "\n",
    "\tdef query(prompts):\n",
    "\n",
    "\t\tpayload = {\n",
    "\t\t\t'inputs': prompts,\n",
    "\t\t\t'parameters': {\n",
    "\t\t\t\t'max_new_tokens': 250\n",
    "\t\t\t},\n",
    "\t\t}\n",
    "\n",
    "\t\tapi_url = f\"https://api-inference.huggingface.co/models/{model}\"\n",
    "\t\tresponse = requests.post(api_url, headers=headers, json=payload)\n",
    "\t\treturn response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['api_or_endpoint'] == 'endpoint':\n",
    "\n",
    "\tendpoint = hfhub.get_inference_endpoint(config['endpoint'])\n",
    "\tdef query(abstracts, preprompt=\"summarize in two sentences:\"):\n",
    "\n",
    "\t\tprompts = [\n",
    "\t\t\tf\"{preprompt}: {abstract}\"\n",
    "\t\t\tfor abstract in abstracts\n",
    "\t\t]\n",
    "\n",
    "\t\tpredictions = [\n",
    "\t\t\tendpoint.client.text_generation(\n",
    "\t\t\t\tprompt,\n",
    "\t\t\t\tmax_new_tokens=1000,\n",
    "\t\t\t) for prompt in prompts\n",
    "\t\t]\n",
    "\t\treturn predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "def wrap(text):\n",
    "    return \"\\n\".join(textwrap.wrap(text, width=80))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the publications most-similar to the original\n",
    "sorted_keys, sorted_values = crt.sort(atl, center=atl.center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the abstracts for the most-similar publications\n",
    "prompt = (\n",
    "'''The following text are abstracts from several publications that are most\n",
    "similar to the original publication. We will share each one, and then we will\n",
    "summarize them.\n",
    "'''\n",
    ")\n",
    "abstracts = []\n",
    "for i, identifier in enumerate(sorted_keys[:config['n_summarized']]):\n",
    "\n",
    "    abstract = \"\\n\".join(atl.publications[identifier].abstract.split(\".\"))\n",
    "\n",
    "    # Combined prompt; used for LLMs\n",
    "    prompt += f\"This is the abstract for paper {i+1}:\\n\"\n",
    "    prompt += abstract + \"\\n\"\n",
    "\n",
    "    # Individual prompts; used for summarization models\n",
    "    abstracts.append(abstract)\n",
    "\n",
    "prompt += \"The summary of the papers, with one sentence per paper, is as follows:\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = query(abstracts)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import HTTPError\n",
    "overall_summary_input = \"\\n\\n\".join([\n",
    "    \"Summary for paper 1: \" + prediction\n",
    "    for prediction in predictions\n",
    "])\n",
    "try:\n",
    "    overall_prediction = query(\n",
    "        [overall_summary_input, ],\n",
    "        preprompt=\"Summarize in a few sentences current the field studied by the following research papers:\",\n",
    "    )[0]\n",
    "except HTTPError as e:\n",
    "    overall_prediction = \"\"\n",
    "print(overall_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score\n",
    "from evaluate import load\n",
    "eval_module = load(\"rouge\")\n",
    "metrics = eval_module.compute(predictions=predictions, references=abstracts, use_aggregator=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretty print\n",
    "output_str = wrap(overall_prediction) + \"\\n\\n\"\n",
    "for i in range(config['n_summarized']):\n",
    "\n",
    "    output_str += f\"Paper {i+1} summary (\"\n",
    "    output_str += f\"n_char_orig: {len(abstracts[i])}, \"\n",
    "    output_str += f\"n_char_summ: {len(predictions[i])}, \"\n",
    "    output_str += f\"rouge2: {metrics['rouge2'][i]:.3g}):\\n\"\n",
    "    output_str += \"-------------------------------------------------------------\\n\"\n",
    "    output_str += wrap(predictions[i])\n",
    "    output_str += \"\\n\\n\"\n",
    "\n",
    "print(output_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
